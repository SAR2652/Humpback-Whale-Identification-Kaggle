{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "#import necessary modules from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#import tensorflow backend\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Flatten, BatchNormalization, Convolution2D , MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of input images and take labels as input\n",
    "training_list = glob.glob('/home/sarvesh/ML_Github/hbwid/training_set/*.jpg')\n",
    "df = pd.read_csv('/home/sarvesh/ML_Github/hbwid/train.csv')\n",
    "training_sorted = sorted([x for x in training_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4786 3808  662    0    0]\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess images from dataset\n",
    "\n",
    "#encode string Ids into numbers by creating a new column 'Id_numeric'\n",
    "le = LabelEncoder()\n",
    "df['Id_numeric'] = le.fit_transform(df['Id'])\n",
    "\n",
    "#sort images in lexicographic order\n",
    "df_sorted = df.sort_values('Image')\n",
    "\n",
    "#drop columns like 'Image' and 'Id' that have string data types \n",
    "df_sorted.drop(['Image', 'Id'], axis = 1, inplace = True)\n",
    "\n",
    "#Select only the first 4000 rows\n",
    "df_sorted = df['Id_numeric'][:7500].values\n",
    "print(df_sorted[:5])\n",
    "print(df_sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to resize image \n",
    "\n",
    "def resize_image(image, inter = cv2.INTER_AREA):\n",
    "    \n",
    "    #specify dimensions of the resized image\n",
    "    dim = (256, 256)\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    \n",
    "    #reshape the image and flatten it out into a single array\n",
    "    #esized = np.reshape(resized, (65536, 1, 3))\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images have been preprocessed and added to final dataset\n",
      "2000 images have been preprocessed and added to final dataset\n",
      "3000 images have been preprocessed and added to final dataset\n",
      "4000 images have been preprocessed and added to final dataset\n",
      "5000 images have been preprocessed and added to final dataset\n",
      "6000 images have been preprocessed and added to final dataset\n",
      "7000 images have been preprocessed and added to final dataset\n",
      "8000 images have been preprocessed and added to final dataset\n"
     ]
    }
   ],
   "source": [
    "#initialize an empty list to store final training images\n",
    "training_images_final = []\n",
    "\n",
    "#initialize counter to check the number of images added\n",
    "count = 0\n",
    "\n",
    "for i in training_sorted:\n",
    "    \n",
    "    #Create a dataset of only 4000 images\n",
    "    if count == 7500:\n",
    "        break\n",
    "        \n",
    "    #read in a color image (channel = 0 i.e. bit depth = 0) \n",
    "    img = cv2.imread(i, 0)\n",
    "    \n",
    "    #obtain resized image from the function in the above cell\n",
    "    img = resize_image(img)\n",
    "    \n",
    "    #append to final list of training images\n",
    "    training_images_final.append(img)\n",
    "    \n",
    "    #increment counter\n",
    "    count = count + 1\n",
    "    \n",
    "    if count % 1500 == 0:\n",
    "        print(\"{} images have been preprocessed and added to final dataset\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(5200, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(training_images_final, df_sorted, \n",
    "                                                    test_size = 0.35, random_state = 42)\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "print(type(y_train))\n",
    "print(X_train.shape)\n",
    "\n",
    "#assign None to training_images_final to save memory\n",
    "#training_images_final = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200 256 256\n"
     ]
    }
   ],
   "source": [
    "# flatten 256*256 images to a 65536 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "print(\"{} {} {}\".format(X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_val = X_val.reshape(X_val.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 4998)\n",
      "(2800, 5002)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "num_classes = y_val.shape[1]\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the lengths of the training and testing sets as well as the batch size\n",
    "train_length = len(X_train)\n",
    "val_length = len(X_val)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Neural Network\n",
    "\n",
    "#Specify the type of model being used\n",
    "model = Sequential()\n",
    "\n",
    "#Add layers to the model\n",
    "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "#model.add(Dense(128, input_shape = (256, 256, 3)))  #As each image has resolution 256x256\n",
    "#model.add(Dense(256, activation = \"relu\"))\n",
    "#model.add(Convolution2D(64, (3, 3), activation = 'relu'))\n",
    "#model.add(Convolution2D(64, (3, 3), activation = 'relu'))\n",
    "#model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#model.add(Convolution2D(128, (3, 3), activation = 'relu'))\n",
    "#model.add(Convolution2D(128, (3, 3), activation = 'relu'))\n",
    "#model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#model.add(Dense(512, activation = 'relu'))\n",
    "#model.add(Dense(128, activation = 'softmax'))  #Softmax function needs one node for every output class\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "\n",
    "#review the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional approach :\n",
    "#Here we take only 1000 images (small dataset) for the purpose of training and validation\n",
    "#Generators are created to create different images from the same image\n",
    "#with some sort of augmentation in terms of rotation, shearing or translation etc\n",
    "#using ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional approach : \n",
    "\n",
    "#Prepare data from training and validation sets\n",
    "train_generator = train_datagen.flow(np.array(X_train), y_train, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(np.array(X_val), y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional approach :\n",
    "\n",
    "#fit data to the generator\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch = train_length // batch_size,\n",
    "    epochs=30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=  val_length // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=batch_size, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
